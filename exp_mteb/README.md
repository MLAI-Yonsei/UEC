# MTEB Evaluation

This document outlines the workflow for running various [Massive Text Embedding Benchmark (MTEB) experiments](https://huggingface.co/spaces/mteb/leaderboard). The process involves several distinct steps, from generating probabilistic embeddings to evaluating different ensemble and model merging techniques.

### Workflow Overview

1.  **[Optional] Probabilistic Model Generation (`fit_la.py`)**: If you plan to run UEC evaluations, you first need to convert standard embedding models into probabilistic ones by fitting a Laplace Approximation.
2.  **Individual Model Evaluation & Caching (`run_individual.py`)**: To create a baseline and prepare for embedding-level ensembles, evaluate individual models on MTEB. This step also generates cached embeddings required for `run_ensemble.py`.
3.  **[Optional] Probabilistic Embedding Caching (`cache.py`)**: For UEC evaluation, this script runs the probabilistic models on MTEB tasks to generate and cache the mean and variance embeddings required by `run_uec.py`.
4.  **Embedding Ensemble Evaluation (`run_ensemble.py`)**: Use the standard embeddings cached by `run_individual.py` to evaluate the performance of simple ensemble techniques (uniform and weighted averaging).
5.  **Model Merging Evaluation (`run_merging.py`)**: Instead of ensembling embeddings, this step merges the models themselves at the parameter level and evaluates the resulting single model.
6.  **Uncertainty-Aware Ensemble Evaluation (`run_uec.py`)**: Evaluate the performance of Uncertainty-driven Embedding Convolution (UEC), which uses the probabilistic embeddings cached by `cache.py`.

---

### 1. Probabilistic Model Generation (`fit_la.py`)

This script fits a Laplace Approximation to a standard pre-trained embedding model using the MS MARCO and SNLI datasets. This creates a probabilistic version of the model that can provide uncertainty estimates along with its embeddings. This is a prerequisite for `cache.py`.

**Example Usage:**

```bash
python exp_mteb/fit_la.py \
    --model_name "intfloat/e5-base-v2" \
    --save_path_template "/path/to/your/bem/la_models/{model_folder_name}/{backend}" \
    --backend AsdlEF \
    --evaluation
```

**Key Arguments:**

*   `--model_name`: The HuggingFace identifier for the model to which the Laplace Approximation will be fitted.
*   `--save_path_template`: A template for the directory where the fitted Laplace model will be saved. **You must change `/path/to/your/bem/` to your actual path.**
*   `--backend`: The backend library for Hessian computation (e.g., `AsdlEF`).
*   `--force_retrain`: If specified, forces retraining even if a saved model already exists at the target path.
*   `--evaluation`: A flag to trigger an evaluation of the model's performance after fitting.

---

### 2. Individual Model Evaluation & Caching (`run_individual.py`)

This script runs the standard MTEB evaluation for a single model. A crucial side effect of this process is that MTEB caches the embeddings for all evaluated tasks. These caches are required for `run_ensemble.py`.

**Example Usage:**

```bash
# Repeat this for every model you want to include in an ensemble
python exp_mteb/run_individual.py \
    --model_name "BAAI/bge-base-en-v1.5" \
    --task all \
    --output_folder "/path/to/your/bem/cache" \
    --batch_size 128
```

**Key Arguments:**

*   `--model_name`: The HuggingFace identifier of the model to evaluate.
*   `--task`: The category of MTEB tasks to run (`retrieval`, `classification`, `sts`, or `all`).
*   `--output_folder`: The root directory where MTEB results and, most importantly, the **embedding caches** will be saved. The script will create a subdirectory named after the model (e.g., `/path/to/your/bem/cache/BAAI/bge-base-en-v1.5`).
*   `--batch_size`: The batch size for the MTEB evaluation.

---

### 3. Probabilistic Embedding Caching (`cache.py`)

This script runs the probabilistic models (generated by `fit_la.py`) on MTEB tasks. Its main purpose is not the evaluation results, but to generate and cache the probabilistic embeddings (mean and variance) for each task. These caches are a prerequisite for `run_uec.py`.

**Example Usage:**

```bash
python exp_mteb/cache.py \
    --model_names "BAAI/bge-base-en-v1.5" "intfloat/e5-base-v2" \
    --la_models_root "/path/to/your/bem/la_models" \
    --scales 1.0 1.0 \
    --cache_root "/path/to/your/bem/cache_proembs" \
    --task_types all
```

**Key Arguments:**

*   `--model_names`: A list of HuggingFace model names to process.
*   `--la_models_root`: The root directory where the fitted Laplace models (from `fit_la.py`) are stored.
*   `--scales`: A list of scaling factors for the posterior variance, one for each model.
*   `--cache_root`: The root directory where the generated probabilistic embedding caches will be saved.
*   `--task_types`: The MTEB task categories to run for caching (`retrieval`, `classification`, `sts`, or `all`).

---

### 4. Embedding Ensemble Evaluation (`run_ensemble.py`)

This script takes the standard embeddings cached by `run_individual.py` and evaluates the performance of simple ensemble strategies.

**Note:** This script contains hardcoded paths to the embedding caches and a hardcoded `MODELS` list. You must modify the script directly if your paths or model list differ.

**Example Usage:**

```bash
# Uniform ensemble
python exp_mteb/run_ensemble.py \
    --ensemble_type uniform \
    --gpus "0"

# Weighted ensemble
python exp_mteb/run_ensemble.py \
    --ensemble_type weight \
    --weights "0.6,0.2,0.2" \
    --gpus "0,1"
```

**Key Arguments:**

*   `--ensemble_type`: The type of ensembling to perform (`uniform` or `weight`).
*   `--weights`: A comma-separated list of floats for the `weight` ensemble type. The number of weights must match the number of models in the script's `MODELS` list.
*   `--gpus`: A comma-separated list of GPU IDs to use.

---

### 5. Model Merging Evaluation (`run_merging.py`)

This script merges multiple pre-trained models at the parameter level to create a new, single model. It supports several merging techniques and evaluates the resulting model on MTEB tasks.

**Example Usage:**

```bash
# Uniform (Average) Merging
python exp_mteb/run_merging.py \
    --merging_technique uniform \
    --model_names BAAI/bge-base-en-v1.5 intfloat/e5-base-v2 \
    --output_name_base uniform_merged_bge_e5

# Weighted Merging
python exp_mteb/run_merging.py \
    --merging_technique weighted \
    --model_names BAAI/bge-base-en-v1.5 intfloat/e5-base-v2 \
    --weights "0.7,0.3" \
    --output_name_base weighted_merged_bge_e5

# Task Vector Merging
python exp_mteb/run_merging.py \
    --merging_technique task_vector \
    --model_names BAAI/bge-base-en-v1.5 intfloat/e5-base-v2 \
    --lambda_scale 0.5 \
    --output_name_base task_vector_merged
```

**Key Arguments:**

*   `--merging_technique`: The merging strategy to use (`uniform`, `weighted`, `task_vector`).
*   `--model_names`: A list of HuggingFace model identifiers to merge. For `task_vector`, the first model is the base.
*   `--weights`: Comma-separated weights for `weighted` merging.
*   `--lambda_scale`: The scaling factor (lambda) for the task vector in `task_vector` merging.
*   `--output_name_base`: A base name for the directory where the merged model will be saved.
*   `--batch_size`: Batch size for the subsequent MTEB evaluation.

---

### 6. UEC Evaluation (`run_uec.py`)

This script performs Uncertainty-driven Embedding Convolution (UEC) on probabilistic embeddings and evaluates the result on MTEB. It requires the caches generated by `cache.py`.

**Example Usage:**
```bash
python exp_mteb/run_uec.py \
    --model_cache_roots "/path/to/your/bem/cache_proembs" \
    --task_type retrieval \
    --save_root "/path/to/your/bem/uec_ensembled_cache" \
    --output_root "/path/to/your/bem/uec_mteb_results" \
    --beta 0.1 \
    --temperature 2.0
```

**Key Arguments:**

*   `--model_cache_roots`: The root directory containing the pre-generated probabilistic embeddings from `cache.py`.
*   `--task_type`: The category of MTEB tasks to run (`retrieval`, `classification`, `sts`, or `all`).
*   `--save_root`: The root directory where the final ensembled UEC embeddings will be saved.
*   `--output_root`: The root directory for the MTEB evaluation results of the UEC model.
*   `--temperature`: Temperature scaling for softmax in coefficient calculation.
*   `--beta`: A hyperparameter for the uncertainty-aware similarity function's variance penalty.
